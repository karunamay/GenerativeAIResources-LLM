{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zCm_GdCKYDNm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import google.generativeai as palm\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taFqmFg-7_PY"
   },
   "source": [
    "### Grab an API Key\n",
    "\n",
    "To get started, you'll need to [create an API key](https://developers.generativeai.google/tutorials/setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YE1x5qv-hka3"
   },
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyCXA0HyEyG4kQ1f_vTWqX2wY_PIAQdDaQY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'embedText' in m.supported_generation_methods]\n",
    "EMBEDDING_MODEL = models[0].name\n",
    "print(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2dk6P3nJz6m"
   },
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dKLCxpTw_C2Q",
    "outputId": "6dc895da-8cb2-4fb0-ece0-c1ce13b3f363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "COMPLETIONS_MODEL = models[0].name\n",
    "print(COMPLETIONS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answer against your own data- xlsx/csv/etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading open source data - from openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3964 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chile at the 2020 Summer Olympics</th>\n",
       "      <th>Artistic</th>\n",
       "      <td>Chile at the 2020 Summer Olympics Artistic Chi...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France at the 2020 Summer Olympics</th>\n",
       "      <th>Weightlifting</th>\n",
       "      <td>France at the 2020 Summer Olympics Weightlifti...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canoeing at the 2020 Summer Olympics – Women's K-1 200 metres</th>\n",
       "      <th>Schedule</th>\n",
       "      <td>Canoeing at the 2020 Summer Olympics – Women's...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boxing at the 2020 Summer Olympics – Men's middleweight</th>\n",
       "      <th>Qualification</th>\n",
       "      <td>Boxing at the 2020 Summer Olympics – Men's mid...</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cycling at the 2020 Summer Olympics – Qualification</th>\n",
       "      <th>Road cycling</th>\n",
       "      <td>Cycling at the 2020 Summer Olympics – Qualific...</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            content  \\\n",
       "title                                              heading                                                            \n",
       "Chile at the 2020 Summer Olympics                  Artistic       Chile at the 2020 Summer Olympics Artistic Chi...   \n",
       "France at the 2020 Summer Olympics                 Weightlifting  France at the 2020 Summer Olympics Weightlifti...   \n",
       "Canoeing at the 2020 Summer Olympics – Women's ... Schedule       Canoeing at the 2020 Summer Olympics – Women's...   \n",
       "Boxing at the 2020 Summer Olympics – Men's midd... Qualification  Boxing at the 2020 Summer Olympics – Men's mid...   \n",
       "Cycling at the 2020 Summer Olympics – Qualifica... Road cycling   Cycling at the 2020 Summer Olympics – Qualific...   \n",
       "\n",
       "                                                                  tokens  \n",
       "title                                              heading                \n",
       "Chile at the 2020 Summer Olympics                  Artistic           79  \n",
       "France at the 2020 Summer Olympics                 Weightlifting     126  \n",
       "Canoeing at the 2020 Summer Olympics – Women's ... Schedule           43  \n",
       "Boxing at the 2020 Summer Olympics – Men's midd... Qualification     236  \n",
       "Cycling at the 2020 Summer Olympics – Qualifica... Road cycling      166  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading open source data - from openai\n",
    "df = pd.read_csv('https://cdn.openai.com/API/examples/data/olympics_sections_text.csv')\n",
    "df['content']=df['title']+' '+df['heading']+ ' '+df['content']\n",
    "df = df.set_index([\"title\", \"heading\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = palm.generate_embeddings(\n",
    "      model=EMBEDDING_MODEL,\n",
    "      text=text\n",
    "    )\n",
    "    return result[\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document_embeddings = compute_doc_embeddings(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could directly use the dataframe for QA, but because of the token limitations for the LLMs, we have to first get a most relevant context based on the question from the given dataframe,and then pass that with question in the formatted prompt to get the desired answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configs\n",
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatted prompt creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting desired answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array],\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = palm.generate_text(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response.candidates[0]['output'].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1 document sections:\n",
      "('2020 Summer Olympics', 'Postponement to 2021')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'due to the COVID-19 pandemic'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=answer_query_with_context(\"Why was the 2020 Summer Olympics originally postponed?\", df, document_embeddings)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_quickstart.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (llamaM1)",
   "language": "python",
   "name": "llamam1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
