{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d75e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b21cba",
   "metadata": {},
   "source": [
    "# By default, GPT-3 isn't an expert on the 2020 Olympics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4660f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Marcelo Chierighini of Brazil won the gold medal in the men's high jump at the 2020 Summer Olympics.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
    "openai.api_key = 'XXXXXXXXXXXXXXXXXX'\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e726815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 houses x 3 cats = 9 cats\\n\\n9 cats x 4 mittens = 36 mittens\\n\\n36 mittens x 7m of yarn = 252m of yarn for mittens\\n\\n9 cats x 1 hat = 9 hats\\n\\n9 hats x 4m of yarn = 36m of yarn for hats\\n\\n252m of yarn for mittens + 36m of yarn for hats = 288m of yarn total'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I have three houses, each with three cats.\n",
    "each cat owns 4 mittens, and a hat. Each mitten was\n",
    "knit from 7m of yarn, each hat from 4m.\n",
    "How much yarn was needed to make all the items?\n",
    "\n",
    "Think about it step by step, and show your work.\n",
    "\"\"\"\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26805356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer architecture is a type of artificial intelligence (AI) model that uses a self-attention mechanism to process input data. It is based on a neural network architecture that uses multiple layers of nodes to process data. The self-attention mechanism allows the model to focus on specific parts of the input data, allowing it to better understand the data and make more accurate predictions. Transformer architecture has been used in a variety of applications, including natural language processing, image recognition, and machine translation. It has become increasingly popular due to its ability to process large amounts of data quickly and accurately.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert at giving advises.\n",
    "\n",
    "Create a summary about transfomer architecure for a a layman.\n",
    "\n",
    "\"\"\"\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188b57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "OPENAI_API_KEY='XXXXXXXXXXXXXXXXXXXXX'\n",
    "openai.api_key=OPENAI_API_KEY\n",
    "template = \"\"\"USER: {question}\n",
    "ASSISTANT: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53d5893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Let's start by finding out the birth year of Elon Musk, the founder of Tesla and SpaceX. Elon Musk was born on June 28, 1971.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=ChatOpenAI(openai_api_key=openai.api_key,temperature=0)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What year Tesla and SpaceX founder was born?.\"\n",
    "llm_chain.run(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b690d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llamaM1)",
   "language": "python",
   "name": "llamam1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
